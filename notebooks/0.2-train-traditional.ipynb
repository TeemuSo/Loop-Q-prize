{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVtPmUNJf8In"
   },
   "source": [
    "# Traditional machine learning with PCA features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_E7TSpL_7z_4"
   },
   "source": [
    "This notebook explores the traditional machine techniques, and whether they could be used. This notebook deals with features extracted from PCA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hl9G4XiUHeKk"
   },
   "source": [
    "## Preprocess and load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hgEj5Ab8hMD"
   },
   "source": [
    "Import and load all the data. Data should be stored in Google Drive. \n",
    "\n",
    "Data should be separated categorically in to .npz files. This file-sorting can be done as stated in README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x9rMMtuOfIFT",
    "outputId": "383bf1a6-1cf6-45d5-a2f0-4b790873e7dd"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import datetime\n",
    "import io\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.data.preprocess_data import DatasetManager\n",
    "from src.features.dimension_reduction import fit_pca, load_cnn_embedding, extract_cnn_features\n",
    "\n",
    "# S3 bucket\n",
    "import boto3\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QerYjLx_9PGW"
   },
   "source": [
    "Define constants to be used later. *DRIVE_PATH* and *MODEL_PATH* should be the root path of project and path for models, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "l2qoI6r_gc2u"
   },
   "outputs": [],
   "source": [
    "EMOTION_LIST = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "DRIVE_PATH = \"/content/drive/My Drive/Loop Q prize\"\n",
    "MODEL_PATH = 'models/traditional'\n",
    "\n",
    "# Set values\n",
    "BATCH_SIZE = 8\n",
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.2\n",
    "N_EPOCHS = 100\n",
    "INPUT_SIZE = 224\n",
    "N_FEATURES = len(EMOTION_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all of the data in splits to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FEpfZk2v-B_E"
   },
   "outputs": [],
   "source": [
    "dataset_manager = DatasetManager(batch_size=BATCH_SIZE, test_size=TEST_SIZE, \n",
    "                        validation_size=VAL_SIZE, transform=None, \n",
    "                        test_transform=None)\n",
    "data = dataset_manager.load_dataloaders(return_raw_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpack all of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_val = [x[1] for x in data['X'].items()]\n",
    "y_train, y_test, y_val = [x[1] for x in data['y'].items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iC6YKnSKHa0E"
   },
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get descriptors of the images in multiple different ways. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA as image descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform PCA on reasonable amount of components, 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca, X_train_pca, X_test_pca, X_val_pca = fit_pca(X_train, X_test, X_val, n_components = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check cumulatively, how much responsibility first n components have. It seems like 90% of the variance is exaplined by 20 components, but 50 components is also very low representation compared to original, so all components were used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.plot(100 * np.cumsum(pca.explained_variance_ / pca.explained_variance_.sum()))\n",
    "plt.xlabel(\"component\")\n",
    "plt.ylabel(\"percentage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of oriented Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of oriented Gradients (HoG) constructs feature descriptors that take gradient orientation in to account. Visually inspecting the dataset, it seems like data is fairly free of occlusions and such, so HoG could make good sense to use as feature descriptor. pixels_per_cell was manually chosen to 10. Much lower would result in long feature vector, and much higher would then sacrifice in quality of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "\n",
    "ppc = 10\n",
    "train_imgs = [hog(x, orientations=8, pixels_per_cell=(ppc, ppc)) for x in X_train]\n",
    "val_imgs = [hog(x, orientations=8, pixels_per_cell=(ppc, ppc)) for x in X_val]\n",
    "\n",
    "X_train_hog = np.vstack(train_imgs)\n",
    "X_val_hog = np.vstack(val_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN as feature extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN is also powerful feature extractor, and it will be used here to compare the results. The model will be EfficientNet. Embeddings are of size 1280x7x7, so we need to reduce their dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features, and save them locally. This needs to be done only once, and later we can load the features from disk. *np.vstack* takes only equal length arrays, so we only add batch if its of length *BATCH_SIZE*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(INPUT_SIZE),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "dataset_manager = DatasetManager(batch_size=BATCH_SIZE, test_size=TEST_SIZE, \n",
    "                        validation_size=VAL_SIZE, transform=test_preprocess, \n",
    "                        test_transform=test_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2015/2015 [00:55<00:00, 36.44it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 630/630 [00:17<00:00, 36.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 504/504 [00:13<00:00, 36.96it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, val_loader = dataset_manager.load_dataloaders()\n",
    "# Train\n",
    "embeddings, labels = extract_cnn_features(model, train_loader, BATCH_SIZE)\n",
    "np.save('../data/processed/y_train_labels.npy', np.vstack(labels))\n",
    "np.save('../data/processed/X_train_embeddings.npy', np.vstack(embeddings))\n",
    "# Test\n",
    "embeddings, labels = extract_cnn_features(model, test_loader, BATCH_SIZE)\n",
    "np.save('../data/processed/y_test_labels.npy', np.vstack(labels))\n",
    "np.save('../data/processed/X_test_embeddings.npy', np.vstack(embeddings))\n",
    "# Val\n",
    "embeddings, labels = extract_cnn_features(model, val_loader, BATCH_SIZE)\n",
    "np.save('../data/processed/y_val_labels.npy', np.vstack(labels))\n",
    "np.save('../data/processed/X_val_embeddings.npy', np.vstack(embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings should be loaded from disk, as they take up to 6GB of ram. With np.memmap, we can load them sequentially from disk only when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embed, y_train_cnn = load_cnn_embedding('train')\n",
    "X_test_embed, y_test_cnn = load_cnn_embedding('test')\n",
    "X_val_embed, y_val_cnn = load_cnn_embedding('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reduce the dimensionality with PCA, as its efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca, X_train_cnn, X_test_cnn, X_val_cnn = fit_pca(X_train_embed, X_test_embed, X_val_embed, n_components=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "from sklearn.base import clone\n",
    "def save_classifiers(model: List, model_name: List[str]):\n",
    "    for clf, name in zip(model, model_name):\n",
    "        model_type = name.split('_')[0]\n",
    "        if model_type == 'cnn':\n",
    "            dump(clf, f'../models/cnn_features/{name}.joblib')\n",
    "        if model_type == 'pca':\n",
    "            dump(clf, f'../models/pca_features/{name}.joblib')\n",
    "        if model_type == 'hog':\n",
    "            dump(clf, f'../models/hog_features/{name}.joblib')\n",
    "    \n",
    "def train_sklearn_clf(clf, X_train, X_val, y_train, y_val):\n",
    "    model = make_pipeline(StandardScaler(), clone(clf))\n",
    "    model = model.fit(X_train, y_train)\n",
    "    score = model.score(X_val, y_val)\n",
    "    return model, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hog: 0.40476190476190477, pca: 0.34945436507936506, cnn: 0.4208829365079365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "pca_knn, pca_knn_score = train_sklearn_clf(clf, X_train_pca, X_val_pca, y_train, y_val)\n",
    "hog_knn, hog_knn_score = train_sklearn_clf(clf, X_train_hog, X_val_hog, y_train, y_val)\n",
    "cnn_knn, cnn_knn_score = train_sklearn_clf(clf, X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn)\n",
    "\n",
    "# Save models\n",
    "save_classifiers([pca_knn, hog_knn, cnn_knn], ['pca_knn', 'hog_knn', 'cnn_knn'])\n",
    "print(f\"hog: {hog_knn_score}, pca: {pca_knn_score}, cnn: {cnn_knn_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hog: 0.3774801587301587, pca: 0.36507936507936506, CNN: 0.5220734126984127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0, C=0.316, max_iter=2000, verbose=1)\n",
    "pca_lr, pca_lr_score = train_sklearn_clf(clf, X_train_pca, X_val_pca, y_train, y_val)\n",
    "hog_lr, hog_lr_score = train_sklearn_clf(clf, X_train_hog, X_val_hog, y_train, y_val)\n",
    "cnn_lr, cnn_lr_score = train_sklearn_clf(clf, X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn)\n",
    "\n",
    "# Save models\n",
    "save_classifiers([pca_lr, hog_lr, cnn_lr], ['pca_lr', 'hog_lr', 'cnn_lr'])\n",
    "print(f\"hog: {hog_lr_score}, pca: {pca_lr_score}, CNN: {cnn_lr_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teemu\\anaconda3\\envs\\pytorchEnv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:49:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teemu\\anaconda3\\envs\\pytorchEnv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:49:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teemu\\anaconda3\\envs\\pytorchEnv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:50:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "hog: 0.4417162698412698, pca: 0.3933531746031746, cnn: 0.5131448412698413\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier()\n",
    "pca_xgb, pca_xgb_score = train_sklearn_clf(clf, X_train_pca, X_val_pca, y_train, y_val)\n",
    "hog_xgb, hog_xgb_score = train_sklearn_clf(clf, X_train_hog, X_val_hog, y_train, y_val)\n",
    "cnn_xgb, cnn_xgb_score = train_sklearn_clf(clf, X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn)\n",
    "\n",
    "save_classifiers([pca_xgb, hog_xgb, cnn_xgb], ['pca_xgb', 'hog_xgb', 'cnn_xgb'])\n",
    "print(f\"hog: {hog_xgb_score}, pca: {pca_xgb_score}, cnn: {cnn_xgb_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teemu\\anaconda3\\envs\\pytorchEnv\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\teemu\\anaconda3\\envs\\pytorchEnv\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hog: 0.37723214285714285, pca: 0.35987103174603174, CNN: 0.5181051587301587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teemu\\anaconda3\\envs\\pytorchEnv\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(C=0.316)\n",
    "pca_svc, pca_svc_score = train_sklearn_clf(clf, X_train_pca, X_val_pca, y_train, y_val)\n",
    "hog_svc, hog_svc_score = train_sklearn_clf(clf, X_train_hog, X_val_hog, y_train, y_val)\n",
    "cnn_svc, cnn_svc_score = train_sklearn_clf(clf, X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn)\n",
    "\n",
    "save_classifiers([pca_svc, hog_svc, cnn_svc], ['pca_svc', 'hog_svc', 'cnn_svc'])\n",
    "print(f\"hog: {hog_svc_score}, pca: {pca_svc_score}, CNN: {cnn_svc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVC assumes we can separate features with linear kernel mapping. However this might not be the case, especially with low amount of features (PCA reduced data). We use Radial Basis Function -kernel to map data to infinite dimensional space, where accuracy is guaranteed to be higher, but so is the training and inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hog: 0.4270833333333333, pca: 0.4020337301587302, CNN: 0.5285218253968254\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='rbf', C=0.316)\n",
    "pca_rbf_svc, pca_rbf_svc_score = train_sklearn_clf(clf, X_train_pca, X_val_pca, y_train, y_val)\n",
    "hog_rbf_svc, hog_rbf_svc_score = train_sklearn_clf(clf, X_train_hog, X_val_hog, y_train, y_val)\n",
    "cnn_rbf_svc, cnn_rbf_svc_score = train_sklearn_clf(clf, X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn)\n",
    "\n",
    "save_classifiers([pca_rbf_svc, hog_rbf_svc, cnn_rbf_svc], ['pca_rbf_svc', 'hog_rbf_svc', 'cnn_rgf_svc'])\n",
    "print(f\"hog: {hog_rbf_svc_score}, pca: {pca_rbf_svc_score}, CNN: {cnn_rbf_svc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hog: 0.3385416666666667, pca: 0.29464285714285715, CNN: 0.4680059523809524\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier()\n",
    "pca_sgd_svc, pca_sgd_svc_score = train_sklearn_clf(clf, X_train_pca, X_val_pca, y_train, y_val)\n",
    "hog_sgd_svc, hog_sgd_svc_score = train_sklearn_clf(clf, X_train_hog, X_val_hog, y_train, y_val)\n",
    "cnn_sgd_svc, cnn_sgd_svc_score = train_sklearn_clf(clf, X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn)\n",
    "\n",
    "save_classifiers([pca_sgd_svc, hog_sgd_svc, cnn_sgd_svc], ['pca_sgd_svc', 'hog_sgd_svc', 'cnn_sgd_svc'])\n",
    "print(f\"hog: {hog_sgd_svc_score}, pca: {pca_sgd_svc_score}, CNN: {cnn_sgd_svc_score}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "hl9G4XiUHeKk"
   ],
   "name": "ResNet-50.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
