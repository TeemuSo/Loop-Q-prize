{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVtPmUNJf8In"
   },
   "source": [
    "# Traditional machine learning with PCA features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_E7TSpL_7z_4"
   },
   "source": [
    "This notebook explores the traditional machine techniques, and whether they could be used. This notebook deals with features extracted from PCA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hl9G4XiUHeKk"
   },
   "source": [
    "## Preprocess and load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hgEj5Ab8hMD"
   },
   "source": [
    "Import and load all the data. Data should be stored in Google Drive. \n",
    "\n",
    "Data should be separated categorically in to .npz files. This file-sorting can be done as stated in README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x9rMMtuOfIFT",
    "outputId": "383bf1a6-1cf6-45d5-a2f0-4b790873e7dd"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import datetime\n",
    "import io\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.data.preprocess_data import DatasetManager\n",
    "\n",
    "# S3 bucket\n",
    "import boto3\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QerYjLx_9PGW"
   },
   "source": [
    "Define constants to be used later. *DRIVE_PATH* and *MODEL_PATH* should be the root path of project and path for models, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "l2qoI6r_gc2u"
   },
   "outputs": [],
   "source": [
    "EMOTION_LIST = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "DRIVE_PATH = \"/content/drive/My Drive/Loop Q prize\"\n",
    "MODEL_PATH = 'models/traditional'\n",
    "\n",
    "# Set values\n",
    "BATCH_SIZE = 1\n",
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.2\n",
    "N_EPOCHS = 100\n",
    "INPUT_SIZE = 224\n",
    "N_FEATURES = len(EMOTION_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all of the data in splits to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FEpfZk2v-B_E"
   },
   "outputs": [],
   "source": [
    "dataset_manager = DatasetManager(batch_size=BATCH_SIZE, test_size=TEST_SIZE, \n",
    "                        validation_size=VAL_SIZE, transform=None, \n",
    "                        test_transform=None)\n",
    "data = dataset_manager.load_dataloaders(return_raw_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpack all of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_val = [x[1] for x in data['X'].items()]\n",
    "y_train, y_test, y_val = [x[1] for x in data['y'].items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iC6YKnSKHa0E"
   },
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get descriptors of the images in multiple different ways. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA as image descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pca(X_train, X_test, X_val, n_components):\n",
    "    n_rows_train = X_train.shape[0]\n",
    "    n_rows_test = X_test.shape[0]\n",
    "    n_rows_val = X_val.shape[0]\n",
    "    \n",
    "    X_train_flatten = X_train.reshape(n_rows_train, -1)\n",
    "    X_val_flatten = X_val.reshape(n_rows_val, -1)\n",
    "    X_test_flatten = X_test.reshape(n_rows_test, -1)\n",
    "    \n",
    "    pca = PCA(n_components=n_components, whiten=True).fit(X_train_flatten)\n",
    "    # Apply transformation\n",
    "    X_train = pca.transform(X_train_flatten)\n",
    "    X_test = pca.transform(X_test_flatten)\n",
    "    X_val = pca.transform(X_val_flatten)\n",
    "    \n",
    "    return pca, X_train, X_test, X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform PCA on reasonable amount of components, 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca, X_train_pca, X_test_pca, X_val_pca = fit_pca(X_train, X_test, X_val, n_components = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check cumulatively, how much responsibility first n components have. It seems like 90% of the variance is exaplined by 20 components, so I chose to use it as a reasonable metric. If we would use all of the features / all of the data, then the time complexity would scale to be high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.plot(100 * np.cumsum(pca.explained_variance_ / pca.explained_variance_.sum()))\n",
    "plt.xlabel(\"component\")\n",
    "plt.ylabel(\"percentage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of oriented Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of oriented Gradients (HoG) constructs feature descriptors that take gradient orientation in to account. Visually inspecting the dataset, it seems like data is fairly free of occlusions and such, so HoG could make good sense to use as feature descriptor. pixels_per_cell was manually chosen to 10. Much lower would result in long feature vector, and much higher would then sacrifice in quality of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "\n",
    "ppc = 10\n",
    "train_imgs = [hog(x, orientations=8, pixels_per_cell=(ppc, ppc)) for x in X_train]\n",
    "val_imgs = [hog(x, orientations=8, pixels_per_cell=(ppc, ppc)) for x in X_val]\n",
    "\n",
    "X_train_hog = np.vstack(train_imgs)\n",
    "X_val_hog = np.vstack(val_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN as feature extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding(mode: str):\n",
    "    assert mode in ['train', 'test', 'val'], \"Mode must be either 'train', 'test', or 'val'\"\n",
    "    \n",
    "    X = np.load(f'../data/processed/X_{mode}_embeddings.npy', mmap_mode='r')\n",
    "    y = np.load(f'../data/processed/y_{mode}_labels.npy', mmap_mode='r')\n",
    "    y = y.reshape(-1)\n",
    "    return X, y\n",
    "\n",
    "def extract_features(model, loader):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm(loader):\n",
    "            X, y = X.to(device), y\n",
    "            features = model.extract_features(X)\n",
    "            # Flatten features\n",
    "            feat_flat = features.detach().flatten(1).cpu().numpy()\n",
    "            \n",
    "            labels.append(y.numpy())\n",
    "            embeddings.append(feat_flat)\n",
    "            \n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN is also powerful feature extractor, and it will be used here to compare the results. The model will be EfficientNet. Embeddings are of size 1280x7x7, so we need to reduce their dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features, and save them locally. This needs to be done only once, and later we can load the features from disk. *np.vstack* takes only equal length arrays, so we are discarding last batch, since it is of length 5 when others are 8. This should be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▎                                                                                                                                    | 157/16117 [00:35<1:00:12,  4.42it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-236b0ea305b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_manager_torch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_dataloaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/processed/y_train_labels.npy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/processed/X_train_embeddings.npy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-7211cf55d394>\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(model, loader)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[1;31m# Flatten features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mfeat_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\efficientnet_pytorch\\model.py\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m                 \u001b[0mdrop_connect_rate\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blocks\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# scale drop connect_rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop_connect_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;31m# Head\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\efficientnet_pytorch\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, drop_connect_rate)\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_depthwise_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\efficientnet_pytorch\\utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatic_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, val_loader = dataset_manager.load_dataloaders()\n",
    "# Train\n",
    "embeddings, labels = extract_features(train_loader)\n",
    "np.save('../data/processed/y_train_labels.npy', np.vstack(labels)[:-1])\n",
    "np.save('../data/processed/X_train_embeddings.npy', np.vstack(embeddings)[:-1])\n",
    "# Test\n",
    "embeddings, labels = extract_features(test_loader)\n",
    "np.save('../data/processed/y_test_labels.npy', np.vstack(labels)[:-1])\n",
    "np.save('../data/processed/X_test_embeddings.npy', np.vstack(embeddings)[:-1])\n",
    "# Val\n",
    "embeddings, labels = extract_features(val_loader)\n",
    "np.save('../data/processed/y_val_labels.npy', np.vstack(labels)[:-1])\n",
    "np.save('../data/processed/X_val_embeddings.npy', np.vstack(embeddings)[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings should be loaded from disk nonetheless, as they take up to 6GB of ram. With np.memmap, we can load them sequentially from disk only when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embed, y_train_cnn = load_embedding('train')\n",
    "X_test_embed, y_test_cnn = load_embedding('test')\n",
    "X_val_embed, y_val_cnn = load_embedding('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reduce the dimensionality with PCA, as its efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca, X_train_cnn, X_test_cnn, X_val_cnn = fit_pca(X_train_embed, X_test_embed, X_val_embed, n_components=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_classifiers(model: List, model_name: List[str]):\n",
    "    for clf, name in zip(model, model_name):\n",
    "        pickle.dump(clf, open(f'../models/{name}', 'wb'))\n",
    "    \n",
    "def train_sklearn_clf(clf, X_train, X_val, y_train, y_val):\n",
    "    model = make_pipeline(StandardScaler(), clf)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_val, y_val)\n",
    "    return model, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hog: 0.40476190476190477, pca: 0.3521825396825397, cnn: 0.3461729622266402\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "pca_knn, pca_knn_score = train_sklearn_clf(clf, X_train_pca, X_val_pca, y_train, y_val)\n",
    "hog_knn, hog_knn_score = train_sklearn_clf(clf, X_train_hog, X_val_hog, y_train, y_val)\n",
    "cnn_knn, cnn_knn_score = train_sklearn_clf(clf, X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn)\n",
    "\n",
    "# Save models\n",
    "save_classifiers([pca_knn, hog_knn, cnn_knn], ['pca_knn', 'hog_knn', 'cnn_knn'])\n",
    "print(f\"hog: {hog_knn_score}, pca: {pca_knn_score}, cnn: {cnn_knn_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hog: 0.3774801587301587, pca: 0.3663194444444444, CNN: 0.4721669980119284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0, C=0.316, max_iter=2000, verbose=1)\n",
    "pca_lr, pca_lr_score = train_sklearn_clf(clf, X_train_pca, X_val_pca, y_train, y_val)\n",
    "hog_lr, hog_lr_score = train_sklearn_clf(clf, X_train_hog, X_val_hog, y_train, y_val)\n",
    "cnn_lr, cnn_lr_score = train_sklearn_clf(clf, X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn)\n",
    "\n",
    "# Save models\n",
    "save_classifiers([pca_lr, hog_lr, cnn_lr], ['pca_lr', 'hog_lr', 'cnn_lr'])\n",
    "print(f\"hog: {hog_lr_score}, pca: {pca_lr_score}, CNN: {cnn_lr_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teemu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:54:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teemu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:54:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "hog: 0.4417162698412698, pca: 0.4052579365079365\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier()\n",
    "pca_xgb, pca_xgb_score = train_xgboost(clf, X_train_pca, X_val_pca, y_train, y_val)\n",
    "hog_xgb, hog_xgb_score = train_xgboost(clf, X_train_hog, X_val_hog, y_train, y_val)\n",
    "cnn_xgb, cnn_xgb_score = train_sklearn_clf(clf, X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn)\n",
    "\n",
    "save_classifiers([pca_xgb, hog_xgb, cnn_xgb], ['pca_xgb', 'hog_xgb', 'cnn_xgb'])\n",
    "print(f\"hog: {hog_xgb_score}, pca: {pca_xgb_score}, cnn: {cnn_xgb_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teemu\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hog: 0.37896825396825395, pca: 0.3611111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teemu\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(C=0.316)\n",
    "pca_svc, pca_svc_score = train_sklearn_clf(clf, X_train_pca, X_val_pca, y_train, y_val)\n",
    "hog_svc, hog_svc_score = train_sklearn_clf(clf, X_train_hog, X_val_hog, y_train, y_val)\n",
    "cnn_svc, cnn_svc_score = train_sklearn_clf(clf, X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn)\n",
    "\n",
    "save_classifiers([pca_svc, hog_svc, cnn_svc], ['pca_svc', 'hog_svc', 'cnn_svc'])\n",
    "print(f\"hog: {hog_svc_score}, pca: {pca_svc_score}, CNN: {cnn_svc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVC assumes we can separate features with linear kernel mapping. However this might not be the case, especially with low amount of features (PCA reduced data). We use Radial Basis Function -kernel to map data to infinite dimensional space, where accuracy is guaranteed to be higher, but so is the training and inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hog: 0.4270833333333333, pca: 0.4037698412698413\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='rbf', C=0.316)\n",
    "pca_rbf_svc, pca_rbf_svc_score = train_sklearn_clf(clf, X_train_pca, X_val_pca, y_train, y_val)\n",
    "hog_rbf_svc, hog_rbf_svc_score = train_sklearn_clf(clf, X_train_hog, X_val_hog, y_train, y_val)\n",
    "cnn_rbf_svc, cnn_rbf_svc_score = train_sklearn_clf(clf, X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn)\n",
    "\n",
    "save_classifiers([pca_rbf_svc, hog_rbf_svc, cnn_rgf_svc], ['pca_rbf_svc', 'hog_rbf_svc', 'cnn_rgf_svc'])\n",
    "print(f\"hog: {hog_rbf_svc_score}, pca: {pca_rbf_svc_score}, CNN: {cnn_rbf_svc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hog: 0.33134920634920634, pca: 0.283234126984127, CNN: 0.40357852882703776\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier()\n",
    "pca_sgd_svc, pca_sgd_svc_score = train_sklearn_clf(clf, X_train_pca, X_val_pca, y_train, y_val)\n",
    "hog_sgd_svc, hog_sgd_svc_score = train_sklearn_clf(clf, X_train_hog, X_val_hog, y_train, y_val)\n",
    "cnn_sgd_svc, cnn_sgd_svc_score = train_sklearn_clf(clf, X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn)\n",
    "\n",
    "save_classifiers([pca_sgd_svc, hog_sgd_svc, cnn_sgd_svc], ['pca_sgd_svc', 'hog_sgd_svc', 'cnn_sgd_svc'])\n",
    "print(f\"hog: {hog_sgd_svc_score}, pca: {pca_sgd_svc_score}, CNN: {cnn_sgd_svc_score}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "hl9G4XiUHeKk"
   ],
   "name": "ResNet-50.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
